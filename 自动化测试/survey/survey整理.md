一篇以新颖的方式总结和组织近期研究成果的论文，集成并增加了对该领域工作的理解。一篇调查文章强调现有文献的分类，发展对该领域的观点，并评估趋势。”

# 1. 题目

**Test Input Generation**

- 测试输入生成即针对给定应用进行测试探索
  - 测试输入生成是针对给定的应用让算法或者工具进行测试探索（探索包含测试中对移动应用页面和控件的覆盖率、能发现多少错误，生成的输入能否正确触发应用中存在的问题）
  - 测试输入生成的自动化可以极大程度上覆盖完整的输入空间。同时在提高覆盖率、降低脚本复杂度的同时发现最多数量的错误。
- 移动应用结构可以抽象为图结构
  - 抽象为图结构后使用广度/深度遍历算法来
- 三大主流策略:基于随机、基于模型、基于学习（根据三个策略的异同做对比/或者对一个策略的诞生到现在的发展作详细的研究）
  - 基于随机：Google的monkey测试（最方便实用，在工业实践中应用），在页面上随机点击，点到哪个就触发哪个，完全是随机的。
  - 基于模型：在随机的基础上提出来的，对整个应用的空间或状态进行建模，建模后对模型在一定规则引导下进行探索，有效的提高覆盖度。提高在随机测试中难以出现的情况出现的概率。模型在不同的app中有很大的局限性，不同的app适应不同的模型，在使用中有局限性。
  - 基于学习：在模型的基础上提出。基于强化学习的探索策略，采用激励机制。若探索到了未探索的空间，激励机制会给这个探索更高的激励值。工具会根据激励值的变化来不断的调整它的探索策略。比前面两个覆盖率更高，但成本也相对较高，前期的训练和准备工作较为复杂，普适性不是很强。

# 2. 论文

1. **Wuji: Automatic Online Combat Game Testing Using Evolutionary Deep Reinforcement Learning（Wuji：使用进化深层强化学习的自动在线战斗游戏测试）**
2. **Guided, Stochastic Model-Based GUI Testing of Android Apps（基于随机模型的Android应用程序GUI引导测试）**
   1. **摘要**：移动应用无处不在，运行在复杂的环境中，开发时面临着上市时间的压力。因此，确保它们的正确性和可靠性成为一个重要的挑战。本文介绍了Stoat，一种新的指导方法，用于在Android应用程序上执行基于随机模型的测试。Stoat分两个阶段运行：(1)给定一个应用程序作为输入，它使用动态分析(通过加权UI探索策略增强)和静态分析来逆向工程应用程序的GUI交互的随机模型(2)采用吉布斯抽样法进行迭代突变/优化
   2.  为了应对这一挑战，人们提出了许多技术。符号执行在源代码级别跟踪事件的起源和句柄，并通过不遗余力地探索程序路径来生成测试。随机测试通过生成一系列随机事件来模糊应用程序。进化算法通过随机变异和交叉事件序列来生成测试，以实现其优化目标。基于模型的测试(MBT)是自动化GUI测试的另一种流行方法，它通过模型抽象应用程序行为，然后从模型中派生测试来验证应用程序。然而，从模型中详尽地生成测试来验证应用行为是一件非常困难的事情。
   3. 上述挑战强调了开发有效的基于模型的测试技术以释放其潜力的重要性。为此，我们提出了一种新的**基于随机模型**的测试方法Stoat1 (stochastic model App Tester)，以改进Android应用程序的GUI测试。它旨在从GUI模型全面测试应用程序的功能，并通过加强各种用户/系统交互来验证应用程序的行为。给定一个应用程序作为输入，Stoat的操作分为两个阶段：
      1.  首先，它从应用程序生成一个**随机模型**来描述它的GUI交互。在我们的设置中，应用程序的**随机模型是有限状态机**(FSM)，其边缘与测试生成的概率相关联。特别是，Stoat采用了一种动态分析技术，通过**加权UI探索策略和静态分析来探索应用程序的行为并构建随机模型。**
         - **模型构建**。Stoat首先构造了一个随机有限状态机(FSM)来描述应用程序的行为。它使用动态分析技术，并通过加权UI探索策略进行增强，从而有效地探索应用行为。它通过分析应用程序页面的UI层次结构推断输入事件，并动态地优先执行它们，以最大化代码覆盖率。此外，为了识别一些潜在的丢失事件，执行一个静态分析来扫描应用程序代码中已注册的事件监听器。 Stoat在探索期间记录所有UI事件的执行频率，然后使用它们在模型中生成转换的初始概率值。
      2.  其次，Stoat对随机模型进行迭代突变，并从模型突变体中生成检验。通过干扰概率，Stoat能够生成带有各种事件组合的测试，以充分测试GUI交互，**并有意地将测试转向较少的路径，以检测深层次的bug**。特别地，Stoat采用了一种受Markov Chain Monte Carlo (MCMC)抽样启发的引导搜索算法来搜索“好的”模型——派生的测试预计是多样化的，并实现较高的代码和模型覆盖率。
         - **模型突变、测试生成和执行**。为了彻底测试一个应用程序，Stoat利用第一阶段的模型来迭代地指导测试生成，以获得高覆盖率和显示不同的事件序列。具体来说，Stoat是一个循环:随机变异时间的转换概率随机模型(步骤4),生成的测试(步骤5),随机注入系统级事件(步骤3)分析了静态分析到这些ui层测试来提高MBT(步骤6),回放他们的应用程序(步骤7)和收集测试效果
         - 根据测试结果，Stoat利用Gibbs抽样来决定新提出的模型是否应该被接受或拒绝(第9步)，具有更好的目标值的模型将被接受为下一次迭代的突变和抽样;否则，它将以一定的概率被拒绝，以避免局部最优(如果被拒绝，原模型将被重用)。一旦检测到任何错误(即崩溃或无响应)，将使用相应的测试执行进一步的分析以诊断错误(步骤10)
   4. 此外，Stoat采用了一种简单而有效的策略来增强MBT(基于模型的测试) ：在MCMC抽样期间，随机地将各种系统级事件注入到UI测试中。它避免了将系统级事件合并到行为模型中的复杂性，并进一步施加外部环境的影响来检测复杂的bug。 总之，本文的主要贡献如下：
      - 模型建设。Stoat采用动态分析技术，**通过加权的UI探索策略和静态分析，来有效地探索应用程序行为和构建模型**。这种增强有助于实现更完整的模型，它可以比现有GUI探索工具生成的模型多覆盖17 ~ 31%的代码。
      - 故障检测。我们采用MCMC抽样的一个实例吉布斯抽样来指导基于随机模型的检验。在93个开源应用程序上，Stoat取得了令人满意的覆盖率，并检测出了比最先进的测试工具Monkey和Sapienz多3倍的独特崩溃，这清楚地证明了我们的方法的好处。具体来说，Stoat通过在MBT期间注入系统级事件检测到另外91个崩溃。
      - 实施和评估。我们已经将Stoat作为一个自动化工具，并在谷歌Play的1661个最受欢迎的应用程序上进一步评估了它。Stoat从691个应用程序中检测到2110个独特的崩溃。到目前为止，20个崩溃被确认为真正的故障，8个已经修复。结果表明，Stoat在测试真实应用程序时是有效的。
   5. 应用状态被抽象为应用页面(表示为小部件层次树，其中非叶节点表示布局小部件(如LinearLayout)，叶节点表示可执行小部件(如Button))；当页面的结构(和属性)发生变化时，一个新的状态就会被创建。如果应用程序退出/崩溃，结束状态将被视为最终状态。边缘对应于一个输入事件e，表示一个UI动作。应用程序从一个状态移动到另一个状态
   6. 为每个过渡e分配一个概率值p，表示测试生成中e的选择权值。初始概率值是由模型构建过程中每个事件的执行频率决定的。p最初被分配为e的观测执行时间与所有事件的总执行时间w.r.t. s (e∈s)的比率。
   7.  从模型生成测试。Stoat采用概率策略从随机模型生成事件序列。它从入口状态s0开始，并根据概率值从相应的应用程序状态中选择一个事件，直到达到最大序列长度或结束状态。事件概率值越高，事件被选中的可能性越大。
   8. **3.2模型构建：**
      1.  **Stoat采用动态的UI探索策略，通过静态分析来增强，为被测应用构建随机模型。**动态UI的探索。一个应用程序可以通过不同的ui在不同的页面中导航来提供它的功能。
      2. 三个对提高勘探性能至关重要的观测结果，这构成了我们的加权UI勘探策略的基础:
         1. 事件执行频率。所有UI事件都有机会被执行。事件执行的频率越低，它在后续探索中被选择的可能性就越大。
         2. 类型的事件。不同类型的事件的选择并不相同。例如，与普通UI事件(如点击)相比，导航事件(如后退、滚动和菜单)具有不同的优先级，以确保它们在正确的时间触发，否则它们可能会极大地破坏探索效率。
         3. 未访问的子控件数量。如果一个事件在下一页请求更多的新UI小部件，它将被优先考虑，因为应该在具有新功能的页面上花费更多的精力。
      3. Stoat为每个事件分配一个执行权重，该权重在运行时动态调整。
      4. 算法1概述了随机模型的构建过程。它以一个app作为输入，输出对应的模型M。该算法根据当前应用程序页面上的UI小部件推断出可调用事件E，然后将它们添加到一个事件列表中，该列表存储动态分析期间的所有事件(第6-7行)。选择在页面s上执行具有最大权重(由函数getMaxWeightEvent计算)的事件e(第10- 11行)。函数expandFSM接受返回的状态和执行的事件来构建模型(第15行)。最后，根据观察到的执行时间(第17行和第18-24行)，对所有M的跃迁赋以初始概率值。 UI勘探期间,如果应用程序进入一个未知的状态(例如,应用程序崩溃,退出,成为non-responding,或导航到一个无关的应用程序)执行某些事件后,将重新启动执行restoreApp应用或导航应用回到前一页(12 - 14行)。这个未知状态被认为是最终状态。该事件将被添加到Tabu中，并从进一步执行中排除(第10行)，以防止影响建模效率。  
         - **静态事件识别**。动态分析技术典型地从UI层次推断事件，它只捕获静态GUI布局信息。算法1使用静态分析来识别这些被动态分析遗漏的潜在事件。它通过扫描应用程序代码中的事件监听器来检测事件，然后通过它们唯一的资源id将这些事件与运行时观察到的小部件关联起来。Stoat检测注册在UI小部件(例如，setOnLongClickListener)上的事件，并通过覆盖类方法(例如，oncreateoptionmenu)实现。
         - **压缩模型**。一个应用的状态和转换的数量可以很大，甚至是无界的。为了提高测试效率，**Stoat通过只将结构上不同的页面标识为不同的状态来压缩模型，并合并类似的页面。**具体操作如下:(1)将状态的层次树编码为字符串，并转换为哈希值，有效检测重复状态;（2）微小的UI信息，例如文本变化（TextViews/ edittext的内容）和UI属性更改(例如，RadioButtons/ checkboxes的checked属性)，省略而不创建新的状态;(3) listview只区分为空和非空。
   9. **4.引导随机模型突变：**
      1.  Stoat利用Gibbs抽样来指导随机模型的变异，从而生成一组有代表性的检验。测试套件可以从中找到“好的”模型。我们把这个问题看作是一个由适应度函数引导的优化过程。
      2. **Gibbs吉布斯采样**：
         - Gibbs Sampling是一类从期望的概率分布p(x)中抽取样本的算法，直接抽样比较困难。它从函数λ迭代生成样本，λ与p(x)的密度成正比。抽样过程产生一个马尔可夫链，其中当前样本的选择只依赖于前一个样本。经过多次迭代，这些样本可以很接近期望的分布p(x)，允许从更重要的区域(密度更高的区域)生成更多的样本。
         - 在抽样过程中，一个候选样本将以一定的概率被接受或拒绝，这个概率是通过比较当前样本和候选样本之间的λ值来确定的。
      3. **目标函数**：
         - **设计一个有利于测试套件的目标函数，它可以实现高覆盖率并包含不同的事件序列。这样的测试套件预计会触发更多的程序状态和行为，从而增加检测错误的机会。**
         - 目标函数合了三个指标，即代码覆盖率、模型覆盖率和测试多样性。代码覆盖率衡量应用代码测试的彻底程度（在函数中代码覆盖率被计算为开源应用的语句覆盖率，或者闭源应用的方法覆盖率）；模型覆盖衡量应用程序模型覆盖的完整程度（对于模型覆盖，我们使用边缘覆盖来计算覆盖了多少事件）；测试多样性衡量测试套件中事件序列的多样性，这是覆盖率指标的一个重要补充（设计一个轻量级但有效的度量来评估测试用例的多样性。设T为N大小的测试集{l1，…，li，…lN}, li是一个事件序列。其核心思想是计算N个序列的“质心”，并将它们与“质心”的欧氏距离之和作为T的分集值。直观上，距离越大，T的差异越大，即测试集越不一样）
      4.  **吉布斯抽样引导模型突变:**
          1.  Gibbs抽样是专门设计用于当p (x)是多个随机变量的联合分布时抽取样本的。具体地说，我们让所有的转移概率都是随机变量，并通过对它们的迭代变异来绘制样本。它允许更频繁地从具有“好的”随机模型的区域中抽取样本。我们假设，由优化模型衍生的测试可以获得更高的客观值。
          2.  **随机突变模型**。
              1.  算法2给出了吉布斯抽样引导测试算法。搜索空间是随机模型的域，其中每个样本都是一个随机模型。在每次迭代中，通过改变当前模型M中的迁移概率值，生成一个新的候选模型M。
              2.  应用程序有n个应用状态(s1，…，sn)，每个状态si(1≤i≤n)有k个事件转换（e1，…，ej，…，ek）。Stoatran- domly决定是否改变每个app状态si的转移概率。如果选择状态si，则Stoat将ej的原概率值pj随机突变为一个新的概率值pj '，即pj+mSize或pj-mSize的结果。直觉上，新生成的概率值pj '在pj附近(它可以高于或低于pj)，因此新模型M '可以生成非常不同的事件序列s。 为了加快收敛速度，在实现中将mSize设置为固定值(如0.1)。对于其余的转移概率，应用了类似的过程，但约束p1 ' +…+pj ' +…+pk ' = 1仍然成立。对于其他未选择的状态，它们的转移概率保持不变，以使新的模型M '通过突变的概率值有条件地依赖于之前的模型M。
              3.  为了模拟环境的交互，Stoat随机地将系统级事件注入到从突变模型M '生成的测试T '中(第11-15行)。然后在应用程序上重放T '以验证其行为。利用T’的试验结果来确定M’的验收比。如果T '可以提高目标值，M '将在下一次迭代中发生突变(行19-20)。否则，原M发生突变。算法继续执行，直到测试预算耗尽。如果应用程序崩溃或变得无响应，就会记录一个可疑的错误(第17-18行)，并转储相应的错误堆栈以进行错误诊断。
      5.  **系统级事件**：为了将系统级事件合并到基于模式的测试中，Stoat采用了一种简单而有效的策略，将它们随机注入到ui级事件序列中。这种策略避免了在行为模型中包含系统级事件的复杂性，并进一步交错两种类型的事件来检测复杂的错误。
   10. stoat评估：
       1. 系统事件可以揭示更多意想不到的崩溃
       2. Stoat在UI探索中更有效
       3. Stoat在探测深度崩溃方面更有效。
       4. Stoat也有一些**局限性**。**首先**，在测试期间，Stoat发出一个事件，等待它生效，然后发出下一个事件。这种同步确保了测试的完整性，但是它可能会错过那些只能通过快速操作来证明的bug。 **其次**，Stoat可以从模型中生成“不可行的”事件序列。为了缓解这个问题，Stoat通过对象索引而不是一些易变的属性(例如文本)来定位UI小部件，并在无法定位目标UI时跳过事件。**第三**，Stoat生成的模型仍然不完整，因为它不能捕获UI探索期间所有可能的行为，这仍然是GUI测试[16]的一个重要研究目标。 例如，Stoat在带有不规则手势和特定输入数据格式的应用程序中是无效的。未来的工作可能会整合符号执行、字符串分析或学习算法[38]来解决这些问题。
   11. 基于模型的GUI测试。基于模型的测试(MBT)[23,54]是一种广泛使用的测试方法。一个重要的任务是为测试[17]的系统提取一个合适的抽象(行为)模型。然而，在GUI测试中，手工构建模型是耗时且容易出错的。广泛的研究已经创造了一些工具来自动化这一过程。Android-GUITAR使用事件流图，它只包含事件。这种图通常会产生许多不可行的事件序列，降低了MBT的有效性。AndroidRipper ， MobiGUITAR[2](前者的扩展)，ORBIT和AMOLA使用状态机来表示应用模型。然而，它们实现了简单的UI探索(例如，深度/广度优先)，因此它们的性能有限。swifth使用机器学习技术来动态学习应用程序模型，但其目的是改进探索策略，减少应用程序重启。MonkeyLab记录从应用用户到挖掘统计语言模型的执行轨迹，但目的是生成可重玩的事件序列。MBT中的另一个重要活动是从模型生成测试。传统的方法使用图遍历算法来生成测试，然后完成各种覆盖指标。
   12. Stoat，这是一种新颖的、基于模型的自动化测试方法，用于改进GUI测试。Stoat利用应用程序的行为模型，迭代地优化测试生成，以实现高覆盖率和多样化的事件序列。
3. **AppFlow: Using Machine Learning to Synthesize Robust, Reusable UI Tests（AppFlow：使用机器学习合成健壮、可重用的UI测试）**
   1. AppFlow，一个用于综合高健壮性、高可重用的UI测试的系统。它**利用机器学习来自动识别常见的屏幕和小部件**，使开发人员不必编写特别的、脆弱的逻辑来在测试中使用它们。它使开发者能够为应用类别的主要功能编写一个模块化测试库(例如，购物应用的“添加到购物车”测试)。 然后，**它可以从库中的模块中综合完整的测试，以同样的方式快速测试一个新的应用程序**。通过专注于主要功能，AppFlow提供了“烟雾测试”，不需要太多的手工工作。开发人员可以选择通过添加特定于应用程序的测试来定制AppFlow。
   2. 在UI测试中，有足够的机会重用测试，因为许多应用程序属于同一类别，并实现类似的用户流。同一类别的应用之间共享测试的巨大潜力。如果我们能够为同一类别的应用程序创建一个健壮的、可重用的测试库，就可以节省很多精力。
   3. 本文介绍了AppFlow，一个用于**综合高健壮性、高可重用的UI测试的系统**。它使开发人员——例如那些在“购物应用”社区或测试服务公司的开发人员——能够为给定类别的应用程序的主要功能编写一个**模块化UI测试库。**这个库可以共享开源，也可以存储在测试云服务中。然后，当**开发人员想要测试同一类别的新应用时，他们可以快速地从库中的模块测试中合成完整的测试，只需要几行定制，就可以极大地提高工作效率。**
   4. 通过专注于应用类别的主要功能，AppFlow为每个源代码更改提供“冒烟测试”或构建验证测试，几乎不需要手工工作。这样的测试，即使是不完整的，也可以为开发人员提供快速的反馈，并帮助他们在错误造成更大的影响之前尽早修复错误。开发人员可以选择自定义AppFlow来添加特定于应用程序的测试，或者覆盖默认值来执行完整的回归测试。
   5. AppFlow的一个关键思想是**用机器学习的方法来识别屏幕和小部件**。AppFlow不依赖于开发人员的硬编码逻辑，而是从带有意图标记的屏幕和小部件的训练数据集中学习分类器，使用仔细选择的功能，包括文本、小部件大小、图形图标的图像识别结果和光学字符识别(OCR)结果。**在训练了分类器之后，AppFlow使用它将不同的屏幕和小部件映射到规范的屏幕和小部件**。例如，它将登录屏幕上带有“用户名”、“您的电子邮件”或“example@email.com”的文本编辑框映射到登录页面。用户名，表示用户名小部件。
   6. 这种机器学习方法使AppFlow测试能够**引用规范的屏幕和小部件**，而不是特定于应用程序的屏幕和小部件，从而享受各种好处。首先，只要新的设计能够被AppFlow识别，应用的UI现在就可以在不破坏测试的情况下进化。 其次，应用UI现在可以响应设备因素 作为屏幕大小而不破坏测试。第三，**规范的屏幕和小部件抽象了特定于应用的变化，使得在应用之间共享测试变得很容易。**第四，AppFlow识别屏幕的能力使开发者能够专注于测试屏幕的特定流程，而无需编写大量样板代码，先将应用带到屏幕上，或稍后将应用恢复到以前的状态。这一好处对于可重用性至关重要，
   7. AppFlow的第二个关键思想是，**通过应用可重用的、自包含的测试(称为流)，自动发现应用的行为，并从中合成完整的测试。**为了测试诸如“在商品详情页面，用户可以将商品添加到购物车”这样的特性，开发人员编写了一个包含三个组件的流程:(1)测试的前提条件，如“app必须在商品详情界面”;(2)测试的后置条件，如“app必须在购物车界面”;(3)进行测试的实际步骤，如“app必须在购物车界面” ，单击Add按钮。前置条件和后置条件在本质上类似于Hoare Logic，可以包含应用状态的自定义条件，如loggedin = true(即，用户必须已经登录)。这个流程有双重用途**:它可以用来测试应用程序是否正确实现了该功能，也可以用来将应用程序导航到测试其他功能所需的状态**。具体来说，给定一个流库，**AppFlow会动态地综合完整的测试**，如下所示:它启动应用程序，识别它的状态，找到满足先决条件的激活流，执行每个流，并为达到的每个新状态重复上述操作。
   8. AppFlow的合成有两个主要好处。首先，它**极大地模拟了测试创建**，因为开发人员不再需要编写样板代码来将应用程序带入某个状态或在此之后清理状态。第二，**模块化支持测试重用**。如果测试是作为一个整体指定的，那么测试就很难重用，因为不仅测试场景的实现不同，而且达到场景所需的步骤也不同。相反，**模块化测试可以适当地合成，以适应特定应用的行为**。例如，我们可以创建一个测试库，其中包含两个有或没有欢迎屏幕的登录流，以及两个传递或不传递商品细节屏幕的添加到购物车流。然后，**AppFlow可以为我们想要测试的新购物应用合成正确的测试，混合和匹配模块流**。此外，它还允许AppFlow适应应用的行为变化。AppFlow可以发现应用的新行为，并自动为它们合成相应的测试。
4. Benchmarking Automated GUI Testing for Android against Real-World Bugs（针对真实世界中的bug对Android的自动化GUI测试进行基准测试）
5. Flaky Test Detection in Android via Event Order Exploration（基于事件顺序探索的Android脆弱测试检测）
6. HeteroFuzz: Fuzz Testing to Detect Platform Dependent Divergence for Heterogeneous Applications（HeteroFuzz：用于异质应用的检测平台依赖发散的模糊测试）
7. **Automatic Text Input Generation for Mobile Testing（用于移动测试的自动文本输入生成）**
   1. **摘要**：为了提高移动测试的自动化水平，人们提出了许多设计方案。尽管有了这些改进，提供适当的文本输入仍然是一个突出的障碍，这阻碍了自动化测试方法的大规模采用。关键的挑战是如何在用例上下文中自动生成最相关的文本。例如，需要在移动浏览器应用的地址栏中输入有效的网站地址，才能继续测试应用；歌手的名字应该在音乐推荐应用程序的搜索栏中输入。如果没有适当的文本输入，测试就会失败
   2. 移动设备已经成为我们生活中不可分割的一部分。移动应用程序增长速度很快。因此，开发团队一直处于激烈的竞争中，面临着在最后期限前完成发行的巨大压力。不幸的是，这通常会导致手机应用程序出现漏洞，如运行时应用程序崩溃，UI缺陷。移动测试的目标是在应用发布之前找到它的漏洞。有两种主流的移动测试方法:手动测试和自动化测试。在手动测试中，测试人员手动执行操作以锻炼尽可能多的用例。这种方法的缺点是，它需要大量的人力，因为测试人员需要在整个测试期间与应用程序密切互动。此外，人类测试人员通常专注于在常见用例中演示功能，他们可能经常错过可能触发异常的拐角用例。为了覆盖尽可能多的动作序列，研究人员提出了不同于monkey随机搜索策略的各种新的搜索算法。尽管有了这些改进，但在monkey测试期间提供适当的文本输入仍然是一个突出的障碍，这阻碍了monkey测试方法的大规模采用。在许多用例中，大多数现有技术几乎无法提供有意义的文本输入。
      3.  产生相关输入：输入生成的一个关键要求是生成与上下文相关的输入。
         - Monkey学习测试人员的手工输入，并从统计学上将它们与上下文联系起来，例如动作历史和文本框标签;在预测阶段，猴子会根据观察到的上下文自动预测文本输入。该方法的核心是递归神经网络(RNN)模型。这种模型在许多自然语言过程中取得了巨大的成功
      2. 独立于应用程序的输入生成：输入生成的另一个重要要求是应用程序独立性。**这意味着在一组应用程序上训练的模型也应该适用于其他应用程序**。 在不同的应用程序中使用不同的单词来表示相同的概念，这对应用独立性带来了巨大的挑战。
      3. **系统设计**：
         - monkey测试引擎通过点击屏幕上的按钮来探索手机应用程序。当它遇到文本框时，它从文本输入服务器请求相关的输入。服务器通过进一步将请求分派给人工测试人员或RNN运行实例来解析请求。
         - Monkey利用RNN模型来预测给定上下文中的文本输入值。基本上，给定Monkey测试引擎维护的上下文，模型就可以预测文本输入值。然而，由于我们**预测输入的应用程序与我们训练模型的应用程序不同**，RNN模型可能无法识别Monkey测试期间遇到的一些上下文信息。为了解决这一挑战，我们使用Word2Vec模型改进了RNN模型，该模型有助于**识别语义相似的上下文**，尽管它们的句法形式不同(例如，“Movie”和“Film”)。通过RNN模型和Word2Vec模型的新组合，我们有效地解决了这个问题。
      4. **RNN（循环神经网络）**。 循环允许在网络执行的一个步骤中获得的信息传递到下一个步骤，类似于人类的长期记忆。
      5. **将深度学习应用于输入生成**。在高层次上，我们的方法在训练阶段统计地学习文本输入值和它的上下文之间的相关性(Section IV-B)。然后在预测阶段(Section IV-C)，一旦Monkey需要在文本框中提供一些值，我们的方法就根据Monkey到目前为止观察到的上下文预测值。
         - **训练数据集**：在不失一般性的前提下，我们假设一个简化的用户操作模型。在模型中，我们只对两种类型的UI元素感兴趣:按钮和文本框。许多可点击的UI元素，如菜单和tableview单元格，都具有类似于按钮的行为，因此在我们的模型中**具有相同的抽象**。类似地，接受用户输入的文本字段范围，如安全文本字段和搜索字段，被抽象为文本框。注意，我们的实现完全支持所有这些UI元素。我们只对tap和typeText这两种行为感兴趣，这两种行为是UI元素最具代表性的行为。**训练数据集本质上记录了动作序列<α0，α1，…，αn⟩，其中αi为第i步的用户动作。αn前面的子序列指的是用户到达出现αn的UI屏幕所采取的操作。**
         - **培训阶段**：为了不丢失通用性，我们假设每个标签l或输入值v是一个单词，而不是一个短语。让词表V = L∪V al表示训练数据集中出现的所有标签和输入值的列表。           
           - 每一步，RNN模型接受单词的向量表示作为输入。输入，以及隐藏层的先前状态(也被编码为向量)，被用来预测输出，一个概率向量，它描述了序列中接下来出现的每个单词的概率。**训练的目的是更新RNN模型的参数，使下一个词的预测概率分布接近数据集观察到的真实概率分布。**
           -  给定上下文lα0,lα1，…，lαn，则求出条件概率最大的输入值vαn = x。在训练阶段，我们建立RNN模型来预测条件概率。自动计算模型的内部参数，使**预测的概率分布近似于训练数据集观测到的真实概率分布**。然后，在上下文与文本框输入值之间的概率关联没有显著变化的假设下，使用训练后的模型进行预测。
         - **预测阶段**：模型经过训练后，可以用于预测。一般来说，RNN模型接受一个单词序列作为输入，并输出一个概率向量，该向量描述了词汇表中每个单词在该序列(我们称之为下一个单词)之后立即出现的概率。概率分布的抽样将选择一个具有分布中描述的概率的词。
           -  当Monkey遇到一个文本框时，它将动作历史和文本框的标签序列化为一个序列，然后将该序列发送给训练过的模型，以预测下一个单词的概率分布。最后，对概率分布进行抽样，得到下一个单词的值。
         - **输入生成独立于应用程序**：我们的最终目标是预测我们没有训练过的应用程序的输入。主要的挑战是让输入生成独立于应用程序。 我们的想法是，如**果我们遇到一个在培训阶段没有见过的单词，我们可以利用Word2Vec，将它与一些在培训阶段见过的类似单词联系起来**。我们使用了一个Word2Vec模型，该模型是事先使用非常大的谷歌新闻语料库训练的。 如果两个词的向量表示的相似度低于预先设定的阈值0.7，我们就认为该词在训练数据集中没有对应的词，在预测时直接忽略它。在最坏的情况下，如果单词在确定文本输入值时很重要，那么我们的技术就会降级为传统的Monkey测试。这些情况发生的主要原因是，应用程序属于一个新的类别，与我们训练过的应用程序类型非常不同。
   3. **实现：**
      1. **Monkey Testing Engine**：我们的Monkey在探索动作序列时采用深度优先的搜索策略，即填充当前屏幕上所有文本框元素的值后，依次点击可用的按钮。同一屏幕内的按钮可以按随机顺序或按一定顺序点击(例如，按按钮标签的字母顺序)。在我们的实验中，我们采用了两种选择，并采用了随机顺序。另外，为了避免重复探索同一个屏幕，我们构造了每个屏幕的签名，它由屏幕的标题和屏幕上按钮的标签组成。具有相同签名的屏幕被视为同一屏幕，只探索一次。**我们系统的一个重要设计原则是对动作使用随机探索，对文本输入使用RNN预测。**
   4. 开发了一种基于深度学习的方法来自动生成用于移动测试的文本输入。它在上下文中生成最相关的输入值。此外，我们还利用了Word2Vec模型来实现应用程序独立性。对50多个iOS应用程序的评估证实了我们设计的有效性和效率。
8. Mimic: UI Compatibility Testing System for Android Apps（Mimic：Android应用程序的UI兼容性测试系统）
   1. **摘要**：本文提出了一个Android应用程序的自动化UI兼容性测试系统——Mimic。Mimic是专门为**比较不同设备、不同Android版本和不同应用版本的应用的UI行为而设计的**。如何**测试应用程序在不同环境或内部变化中是否表现一致**。 Mimic允许Android应用程序开发者轻松地对其应用程序进行向后和向前的兼容性测试。它还可以对稳定版本的应用程序和更新版本的应用程序进行清晰的比较。为此**，Mimic允许使用多种测试策略，如随机或顺序测试**。最后，Mimic编程模型允许用比其他类似系统少得多的开发人员工作编写这样的测试。此外，Mimic允许与多个测试设备并行测试，从而加快测试时间。
   2. **简介：**
      - Mimic支持我们所说的**跟随-领导者模型**的测试，**多个测试设备并行使用，但一个设备成为执行一系列UI操作的“领导者”。所有其他设备都跟随leader并执行相同的UI动作序列。**使用这个测试模型，模拟报告在测试运行期间发生的UI兼容性问题，比如使用不同的UI路径，显示不同的UI结构，抛出不同的异常，UI性能的差异，等等。从本质上讲，Mimic的主要重点是**UI兼容性测试**。
      - Mimic的设计选择源于多种测试需求，并且缺乏满足这些需求的实际测试系统。 具体来说，有四种常见的测试场景需要进行UI兼容性测试，
        - 版本兼容性测试，开发者在**不同的Android API版本**上测试他们的应用程序
        - 设备兼容性测试，开发者在**不同的Android设备**上测试他们的应用程序
        - 第三方库测试，即开发者使用其现有应用测试第三方库的新版本
        - ……
      - 手机测试有几个独特的挑战，包括UI版本的兼容性和跨设备、应用程序和操作系统版本的一致性。Mimic通过提供以下两个主要特性来解决上述挑战——(i)**易于使用的编程模型，专门为UI兼容性测试设计的**(ii)**一个管理多个设备和应用程序或Android版本的运行时**。如前所述，它实现了follow-the-leader测试模型。运行时还可以使用图像处理技术捕捉应用在不同版本或设备上的UI的视觉差异。
   3. **动机**
      1. **UI兼容性测试场景：**
         - **向前向后兼容性**:应用开发人员需要确保所有以前的Android版本(向后兼容)和未来版本(向前兼容)的正确性。这种向后或向前的兼容性测试需要跨不同Android版本的UI兼容性测试。
         - **设备多样性**:从智能手机到平板电脑，Android设备类型繁多，屏幕尺寸和分辨率各不相同。为了让应用的UI兼容各种设备，开发者需要在不同类型的设备上测试他们的应用
         - **库版本控制**:大多数Android应用程序依赖第三方库来实现增值功能，如广告、谷歌Play Services(例如谷歌Maps)、可视化、图像处理(例如OpenCV)等。然而，随着时间的推移，这些库会随着新特性的添加而并行发展。当这些第三方库发布一个新版本时，开发者需要测试他们现有的应用是否在不同的第三方库版本中提供相同的一致用户体验。这需要跨不同版本的UI兼容性测试。
         - **应用程序检测**:许多研究人员和公司都对使用Java字节码检测技术感兴趣，这种技术可以在没有任何源代码的情况下修改现有的应用程序。 为了测试这些系统的正确性，研究人员会用他们的仪器自动转换现有的Android应用程序技术(包括UI)，并比较被检测的应用程序和(未检测的)原始应用程序的行为。这就需要UI兼容性测试。
      2. **UI兼容性测试的要求**
   4. **MIMIC设计：**Mimic接受一组应用程序和一个Mimic脚本作为输入。在桌面上运行的Mimic运行时执行脚本，并在连接的设备集上运行指定的测试。“Mimic”的设计目的是**能够扩大测试的应用程序数量和使用的设备数量**。该体系结构由Mimic编程模型管理，该模型提供了以下方法:设置运行时、配置用于测试的设备集、指定要运行的UI测试以及所需属性的规范
      1. **Mimic编程模型**：我们的编程模型提**供了简单的抽象来配置和设置带有多个设备、Android版本和应用版本的测试环境。它通过提供单一设备、单一版本的假象来抽象这种复杂性**，测试人员在这里编写他们的测试逻辑，就好像他们在使用单一设备和应用程序的单一版本一样。此外，我们的编程模型提供了组合测试Android应用的不同方面的能力，通过提供一个表达性的、基于回调的抽象来编写测试。
   5. 虽然我们的评估显示，Mimic可以有效地发现不同版本和设备之间潜在的UI兼容性问题，但它并不适用于所有类型的应用程序
   6.  Mimic不支持系统事件:一些UI动作可以由系统事件触发，例如，日历警报弹出可以由系统警报事件触发。目前，Mimic不支持此类UI事件的测试。然而，通过扩展我们当前的Mimic实现，支持这样的UI事件是可能的;通过Android活动管理器(可通过am命令)，我们可以发送系统事件到应用程序。然而，这可能导致一个广阔的空间探索测试，因为Android有大量的系统事件集。巧妙地缩小了这个空间的大小
   7. 第一种类型是不需要任何源代码的黑盒测试。模糊测试,基于模型的测试属于这一类,但他们关注测试单个应用。Mimic也属于这一类,但它的重点是使用多个设备和版本和测试UI兼容性。另外两种方法是白盒测试和灰盒测试。白盒测试需要完全访问源代码。灰盒测试不需要源代码，但需要对正在测试的应用程序有一定的了解，例如UI元素的id。典型的象征性执行[29]，[34]，[21]使用白盒测试，还有其他系统采用白盒方法[28]或灰盒方法[5]。由于白盒和灰盒方法需要了解正在测试的应用程序，所以它们不适合测试仪器化的应用程序等特定场景。
   8. 在本文中，我们描述了一个新的Android应用的UI兼容性测试系统——Mimic。Mimic支持遵循并行测试的领导模式，**我们指定一个设备执行一系列的UI操作;所有其他设备都跟随这个leader并执行相同的UI动作序列**。这个模型对于不同Android版本、设备类型和应用版本的UI兼容性测试非常有用。Mimic通过一个用于编写测试的简洁编程模型使测试变得容易。**编程模型允许测试人员快速建立测试环境，并表达他们自己的测试逻辑。在执行测试逻辑之后，Mimic会报告UI兼容性问题**，比如抛出不同的异常、使用不同的UI路径、资源使用的差异等等。我们对从谷歌Play下载的几百个Android应用程序的评估显示，Mimic可以有效地检测真实的错误，并报告不同Android或应用程序版本的UI兼容性问题。
9. **Practical GUI Testing of Android Applications via Model Abstraction and Refinement（通过模型抽象和细化实现Android应用程序的实用GUI测试）**
   1. 本文介绍了一种**新的、全自动化的基于模型的**Android应用程序测试方法。与使用静态GUI模型指导测试的现有基于模型的方法不同(例如，模型在测试期间不会演进其抽象，因此通常是不精确的)，我们的方法通过**在测试期间利用运行时信息动态地优化模型**。模型演化的这种能力显著地提高了模型的精度，因此与现有方法相比，大大提高了测试的有效性，这一点我们的评估已经证实了。
   2. **简介**
      1. **Android应用的自动GUI测试**。
         - Monkey是谷歌开发的GUI模糊工具，在没有任何指导的情况下生成纯随机事件作为测试输入。因此，它不能保证引导测试探索统一地遍历gui(即，低活动覆盖率)，并且不能合并用户定义的规则，如输入密码[7]或禁止注销。此外，生成的事件是低级的，带有硬编码的坐标，并且通常很长，这使复制和调试变得复杂。
         - 执行Android GUI测试的另一种方法是基于模型的。模型通常是一个有限状态机，其中每个状态都有一组模型操作，并且状态之间的每个转换都被标记为源状态的一个模型动作。实际上，几乎没有应用程序是自带模型的。因此，现有的测试工具通过分别将GUI操作抽象/映射到建模操作和GUI视图映射到状态来构建基于GUI的模型。 模型至少为GUI测试提供了三种好处。首先，**可以使用模型来指导应用程序的开发**。测试工具可以使用特定的指导遍历模型，系统地生成动作序列，然后回放动作序列，测试[4]应用程序。其次，**基于模型的测试工具生成由高级模型操作而不是低级事件组成的输入序列**，这可以促进[14]的重放。 第三，**适当的抽象可以应用到模型中，这反过来有助于减轻GUI操作的激增**。通过抽象，具有相同行为的许多GUI操作可以映射到相同的模型操作。因为这些GUI操作的行为是相同的，所以测试工具不需要执行它们中的每一个，而是可以在执行模型操作时选择其中一个有代表性的GUI操作
         - 首先，如果模型过于细粒度，由于状态爆炸，测试工具无法系统地探索模型。其次，如果模型过于粗粒度，测试工具就无法收集足够准确的模型动作知识来实现有效的引导(即很难在被测试的应用程序上重放模型动作序列)。特别是，无效的抽象可能将具有不同行为(例如，导致不同目标状态)的多个GUI操作映射到同一个模型操作
         - 本文通过有效的**动态模型抽象**，提出了一种新的、实用的基于模型的Android应用程序自动GUI测试技术APE。在初始阶段，一个默认的抽象被用来启动测试的过程。 这种最初的抽象可能是无效的。**APE基于测试过程中观察到的运行时信息，通过搜索更合适的抽象，一个有效平衡模型大小和精度的抽象，逐步细化模型**。我们的方法不是在固定的抽象粒度上操作，而是根据需要**动态调整粒度**。具体地说，**APE用一个决策树来表示动态抽象，并利用测试期间获得的反馈动态地对其进行调整**。这种基于决策树的模型抽象表示极大地提高了测试的有效性。
   3. **背景**：
      1. A**ndroid应用的GUI**：在Android应用程序中，活动是小部件的组合。这些小部件被组织成一个树状结构，本文将其命名为GUI树。小部件可以是按钮、文本框或具有布局的容器。它支持各种GUI操作，如点击和滑动。一个小部件有四类属性描述它的类型(例如，类)，外观(例如，文本)，功能(例如，可点击和可滚动)，以及兄弟小部件之间的指定顺序(例如，索引)。每个属性都是一个键值对。我们使用i、c和t分别表示索引、类和文本属性的键。例如，一个值为0的索引属性可以用i=0表示。GUI树T是一个有根的、有序的树，其中每个节点w是一个GUI小部件，它有一组属性，用属性(w)表示。
      2. **属性路径**：测试工具需要正确地识别小部件，以积累相关的测试知识。不能使用表示小部件的运行时对象的内存地址来标识小部件，因为可能会多次创建和处理相同的GUI。在GUI树T中，给定小部件wn，节点路径ω =<w1,w2，···，wn⟩是一个从其祖先之一w1到wn的遍历路径上的树节点(即小部件)序列。 **如果第一个节点w1是树的根，则该节点路径称为绝对节点路径，否则称为相对节点路径。**绝对节点路径在树中唯一标识一个小部件。
      3. **基于模型的Android GUI测试** 图2描述了基于模型的测试工具的典型工作流程。这样的工具与被测试的应用程序进行迭代交互。最初，测试工具以空状态机作为模型开始。在每次迭代中，测试工具(1)获得应用程序的当前GUI树，(2)识别现有的、对应的状态，或为该GUI树创建一个新的状态，(3)选择一个模型动作并确定一个具体的GUI动作与应用程序交互。
         -  基于模型的测试工具旨在**探索应用程序以发现新的小部件，并利用应用程序来锻炼已发现的小部件之间的交互**。实际上，现代的Android应用程序通常有大量的小部件。为了减轻这种可伸缩性挑战，基于模型的测试工具**进一步尝试识别等价的GUI操作，并将它们抽象为相同的模型操作，以减少搜索空间**。然而，确定两个小部件是否等效并非易事。完整的属性路径通常包含不相关的信息，这将防止发现两个“语义上”等效的小部件。
         - **状态抽象**。状态抽象指的是**识别等价的GUI树和操作，并将它们分别映射到相同的状态和相同的模型操作的过程**。一般情况下，状态抽象是基于GUI操作的全属性路径的相似性来实现的。具体来说，状态抽象确定两个GUI操作是等价的，前提是:(1)它们具有相同的操作类型;(2)在一定的约简规则下，通过删除不相关的属性，它们的完整属性路径可以被约简为相同的属性路径π。类似地，如果两棵GUI树的所有GUI操作都可以简化为相同的属性路径集，则状态抽象确定它们是等价的。
         - 然而，自动化测试工具并不事先知道被测试的应用程序，只能启发式地定义约简规则。请注意，测试工具可以对不同的小部件应用不同的缩减，以实现适当的抽象粒度。
         -  一个好的状态抽象应该在模型大小和模型精度之间取得平衡。一方面，状态抽象应该是粗糙的，以避免通过容忍与测试无关的gui的差异而导致状态爆炸。另一方面，状态抽象应该精确地建模一个应用程序的运行状态，以便与应用程序交互。
         - 我们从默认抽象开始测试。在测试过程中，我们系统而有效地改进了抽象，使之能够平衡模型的大小和精度。
   4. **方法**：
      1. **动态抽象函数**：如第一节所述，APE的关键新颖之处在于它的动态抽象功能，它可以根据运行时信息动态地适应/改变模型抽象，以平衡模型精度和尺寸。然而，实现动态抽象函数并非易事。首先，**动态抽象函数应该在运行时具有适应性**。所有以前的方法都使用具有固定抽象粒度的静态制作抽象函数。因此，调整抽象需要改变实现静态抽象函数的源代码。第二，动态抽象函数应该是**可泛化**的。对于图1中的例子，抽象函数不仅适用于Ti和Tj，还适用于重新排序文件后的任何GUI树。第三，**动态抽象还应该是人类可解释的**，以便用户可以合并关键规则来进一步改进动态抽象。
      2. **优化抽象函数** APE从一个初始抽象函数开始，并不断地对抽象函数进行细化和粗化，以达到适当的模型精度。一个非常粗糙的抽象函数可以将所有GUI操作映射到相同的模型操作，并将所有GUI树映射到相同的状态。这样的函数构建了一个非常简单的模型，并且这个模型没有非确定性的转换，因为每个GUI树都映射到相同的状态。为了避免这种琐碎的情况，我们首先细化抽象函数，直到没有模型动作抽象超过α GUI动作。
      3. **我们使用阈值α和β的三个要求来衡量模型精度和模型大小之间的平衡。** 
         1. 在一个GUI树中，没有模型操作抽象超过α GUI操作，这意味着我们应该细化每个模型操作，直到它抽象的少于α GUI操作。 
         2. 非确定性转换应该尽可能少，这意味着我们应该不断优化抽象函数，直到没有不确定性转换可以被消除。 
         3. 之前L创建的模型状态没有被L的精炼版本精炼成β新状态。
      4. **勘探策略**：我们提出将随机和贪婪结合到深度优先搜索中。首先，我们发现保留勘探地点可以容忍某些非决定论。例如，APE可以通过持续点击图1中的相同文件来容忍由于访问时间而引起的不确定性。因此，我们发现连接子图，并在跳到其他状态之前尝试探索连接子图中的所有模型动作。接下来，我们只会贪婪地访问每个新添加的未访问的模型操作，其中模型操作由其属性路径匹配。第三，我们随机访问其他模型操作，并为未访问的模型操作提供更高的优先级，或者抽象更多GUI操作。当无法重放转换时，APE会分离目标状态以避免不必要的重放尝试。当通过随机动作再次到达状态时，APE再次将状态附加到模型上。因此，APE不仅发展了状态抽象，而且发展了状态连接。
   5.  APE构建在Monkey之上，可以在模拟器和真实设备上运行。它被设计为Monkey的临时替代品，不需要定制正在测试的应用程序和Android设备。我们已经测试了APE在Android 6和7设备上的兼容性，因为当我们开始开发APE[19]时，它们占据了市场份额。 GUI树使用可访问性API[20]转储，与[18]中使用的API相同。最初的决策树为每个小部件使用Rc。最初，所有状态只有一个决策树。如果一个状态需要改进，我们就用写时复制的方式为它构建一个新的决策树。因此，我们可以在必要时对具有相同完整属性路径的小部件应用不同的抽象
   6. APE有一个通用的、基于决策树的抽象函数表示，以便建立一个良好的测试模型。它还具有一种新的演化机制，可以动态地、不断地更新模型，以达到模型大小和模型精度之间的良好平衡。
10. ReCDroid: Automatically Reproducing Android Application Crashes from Bug Reports（ReCDroid：根据错误报告自动复制Android应用程序崩溃）
11. StoryDroid: Automated Generation of Storyboard for Android Apps（StoryDroid：Android应用程序情节提要的自动生成）
    1. 很难在短时间内完全探索应用程序的所有功能。受电影制作中的故事板概念的启发，我们提出了一个系统StoryDroid，用于自动生成Android应用的故事板，并**协助不同角色高效地审核应**用。具体来说**，StoryDroid提取活动转换图，并利用静态分析技术来呈现UI页面，以可视化呈现的页面中的故事板。UI页面和相应实现代码(如布局代码、活动代码、方法层次结构)之间的映射关系也提供给用户**。我们的综合实验揭示了StoryDroid是有效的，确实有助于应用程序开发。StoryDroid的输出支持一些潜在的应用程序，比如推荐UI设计和布局代码。
12. Collaborative Bug Finding for Android Apps（Android应用程序的协作Bug查找）
13. **ComboDroid: Generating High-Quality Test Inputs for Android Apps via Use Case Combinations（ComboDroid：通过用例组合为Android应用程序生成高质量的测试输入）**
    1. **摘要**：Android应用需要高质量的测试输入，而测试输入的生成仍然是一个开放的挑战。现有的技术不足以探索复杂的应用功能，只有通过长时间的、有意义的、有效的测试输入才能实现。观察到这样的测试输入通常可以分解成相对独立的短用例，本文提出了ComboDroid，一个完全不同的Android应用程序测试框架。ComboDroid获取用于显示特定应用程序功能的用例(手动提供或自动提取)，并系统地枚举梳状图
    2. Android应用程序经常没有经过充分的测试，这是由于缺乏高质量的测试输入来彻底测试应用程序的功能，并显示潜在的bug。现有的自动测试技术在探索复杂的应用程序功能——只有通过长且“有意义的”事件序列才能达到的功能方面存在不足。随机或探索式测试输入生成技术可以快速覆盖表面的应用功能，但很难触及更深层次的应用状态来覆盖复杂的应用。
    3. 为了生成高质量的测试输入来彻底地探索应用程序的功能，我们观察到一个长而有意义的测试输入通常可以分解成相对独立的用例。用例是用于显示指定应用程序功能的短事件序列
    4. 用例，根据它们的定义，几乎开始和结束于静止的应用状态，通常是一个稳定的GUI。因此，我们设计了一种算法来自动识别这种GUI状态，并从长事件序列中提取用例。
    5. 为了有效地生成高质量的用例组合(或简称组合)作为测试输入，我们设计了一种算法来对组合进行分类，以获得最大的测试多样性。特别地，我们定义了对齐关系，它决定两个用例是否连接在相同的静态状态，以删除可能无效的组合。我们还定义了依赖关系，它决定了一个用例是否可以影响另一个用例的行为。为了生成有效的测试输入，我们只生成具有足够数据流多样性的对齐组合
14. Multiple-Entry Testing of Android Applications by Constructing Activity Launching Contexts（通过构建活动启动上下文对Android应用程序进行多条目测试）
15. **Automatic Web Testing Using Curiosity-Driven Reinforcement Learning（基于好奇心驱动的强化学习的Web自动测试）**
16. Sapienz: Multi-objective Automated Testing for Android Applications（Sapienz：Android应用程序的多目标自动化测试）
    1. Sapienz，一种用于Android测试的方法，**它使用基于多目标搜索的测试来自动探索和优化测试序列，最小化长度，同时最大化覆盖和故障揭示。**Sapienz结合了随机模糊，系统和基于搜索的探索，利用种子和多层次的仪器。
    2. 开发人员可能会拒绝较长的序列，因为对调试来说不切实际，而且在实践中也不太可能发生;生成的测试序列越长，它在实践中发生的可能性就越小。因此，自动化测试的一个关键目标是用最短的可能的测试序列找到错误，从而使错误揭示对开发人员更具可操作性。
    3. 我们介绍了Sapienz，这是第一种提供**多目标自动化Android应用探索测试的方法**，旨在最大化代码覆盖率和错误揭示，同时最小化错误揭示测试序列的长度。我们的目标是**产生一个完全自动化的方法，最大限度地利用短测试序列揭示故障**。我们的方法的关键见解是，最小化测试序列长度和最大化其他目标可以结合在一个帕累托优化多目标搜索的Android测试方法。通过使用帕累托最优性，当只有较长的测试序列才会发现错误时，或者当它们需要达到更高的代码覆盖率时，我们不会对它们进行分割。然而，通过使用帕累托最优性，当同样好的时候，Sapienz逐步用较短的测试序列替换较长的序列。
    4. Sapienz支持多级检测，即使只有应用程序的APK文件(而没有其他文件)可用，也仍然适用。它的进化算法不断优化覆盖率，序列长度和崩溃的数量发现，寻求揭示尽可能多的崩溃，同时最小化测试序列的长度。
17. Automatically Translating Bug Reports into Test Cases for Mobile Apps（自动将错误报告转换为移动应用程序的测试用例）
    1. 当用户遇到软件故障时，他们可以选择提交错误报告，并提供有关故障及其发生方式的信息。如果错误报告包含足够的信息，那么开发人员可以尝试重新创建问题并调查它，从而消除其原因。不幸的是，用户提交的错误报告的数量通常很大，分析错误报告和重现其中描述的问题的任务可能非常耗时。为了使这个过程更有效，本文中我们提出了**Yakusu技术**，它结合了程序分析和自然语言处理技术，**从错误报告中生成可执行的测试用例**。对于大多数错误报告，开发人员不必研究报告来重现所描述的问题，并且可以简单地自动使用测试用例。
    2. 大多数软件系统为用户提供了一种提交错误报告的方法，可以是自动的(例如，在错误崩溃的情况下)，也可以是手动的。错误报告的主要目的是收集用户所经历的问题的信息，以便开发人员能够调查这些问题，找到原因，并消除这些原因。为了做到这一点，开发人员通常必须查看错误报告，理解导致问题报告的步骤，尝试重现这些步骤和相应的问题，并调试问题。不幸的是，执行这些任务可能非常耗时，特别是在存在大量错误报告和信息不完整的报告时。
    3. 为了使这个过程更有效，我们提出了Yakusu，一种通过程序分析和自然语言处理技术的结合，**从错误报告生成可执行UI测试用例的技术**。具体来说，Yakusu将应用和漏洞报告作为输入，并分为三个主要阶段进行操作。首先，**分析应用程序，识别UI中可用的元素，生成应用程序的本体**。其次，**分析bug报告，利用生成的本体，并尝试识别用户提供的一组步骤，以重现所报告的问题。**最后，**如果成功，它将尝试生成一个测试用例，通过将识别的步骤映射到实际的UI事件来重新生成问题。**
    4. 在定义Yakusu时，我们必须克服两个主要挑战。首先，从典型的非结构化数据(即错误报告)中提取结构化信息是一项非平凡的任务，因为它涉及解释可能不完整的描述，这些描述使用广泛的、不精确的和上下文相关的语言。 其次，即使用户在错误报告中提供的步骤已经被正确识别，这些步骤和实际UI事件之间通常存在逻辑上的差距，步骤的顺序可能不完整。因此，生成适当地编码错误报告的测试用例常常涉及到搜索可能的解决方案的大空间(例如，事件序列)。
    5.  格式问题在错误报告领域尤其相关，因为最终用户通常没有经验或技术专长来构造步骤列表，使开发人员(或工具)能够轻松地使用这些步骤。此外，基于学习的技术(例如，[5,27])在应用程序特有的句子和术语出现时往往表现不佳。相反地，Yakusu可以利用它生成的应用本体来处理这些情况，并使用它来匹配这些特定的应用术语。使用本体技术还可以帮助Yakusu在不采用特定格式的情况下处理报告，因为本体允许该技术将句子中的单词与UI中的元素匹配，然后通过分析元素在运行时的行为推断出相应的操作。
18. **Reinforcement Learning Based Curiosity-Driven Testing of Android Applications（基于强化学习的好奇心驱动的Android应用程序测试）**
    1. **摘要**：移动应用在我们的日常生活中扮演着重要的角色，但如何保证其正确性仍然是一个挑战。基于模型和系统的方法已应用于Android GUI测试。然而，由于模型不精确和可伸缩性差等限制，与随机方法相比，它们并没有显示出显著的优势。在本文中，我们提出了**q -测试，一种基于强化学习的方法**，受益于随机和基于模型的方法的自动化测试的机器人应用。Q-测试以一**种好奇心驱动的策略**来探索Android应用程序，利**用内存集来记录之前访问过的部分状态，并指导测试不熟悉的功能。**本文提出了一种状**态比较模块**，**该模块是由大量收集的样本训练而成的神经网络，用于在函数场景粒度上划分不同的状态。**它可以确定q -测试中的**强化学习奖励**，并帮助好奇心驱动策略有效地探索不同功能。 
    2. **简介**：
       1. **随机策略**产生伪随机事件来模糊被测应用。Monkey被认为是实践状态测试工具，是这种策略的一个典型例子。尽管在实际开发中被广泛采用，但其缺点也相当明显。Monkey通常会生成无用的事件，比如点击屏幕上的非交互区域，而不会改变当前状态。此外，测试是不平衡的，一些难以达到的功能可能永远不会被探索。
       2. **基于模型的策略**根据静态或动态构建的应用程序模型生成测试用例。 在这种情况下，为了获得良好的测试结果，高质量的模型是极其重要的。然而，如上所述，探索Android应用程序的所有状态是一项挑战。更重要的是，几乎不可能精确地模拟应用程序的行为。例如，欢迎界面在现在的应用程序中很常见，只有当应用程序第一次打开时才会出现。这一信息往往无法捕获，导致生成的事件序列总是在欢迎界面中包含事件，这与应用的实际行为不一致，对测试的有效性非常不利。
       3. **系统策略**使用复杂的技术，如符号执行，为目标应用行为提供特定的输入。这些策略的主要目的是揭示那些很难用其他策略执行的典型功能，但是它们的可伸缩性较差，并且在总体测试指标(如代码覆盖率和漏洞揭示)中往往表现得更差。
       4. **<u>机器学习技术</u>**利用强化学习，特别是q学习，它可以受益于随机和基于模型的方法，来指导测试进展。Q表记录了每个事件的值以及Q值的传播特性，可以部分替代模型以一种轻松的方式存储测试相关信息。它还有助于避免模型和应用程序实际行为之间的不一致问题，这是随机测试的优势。但是，现有的工作并没有充分发挥强化学习在Android测试中的能力。**以奖励给予过程为例，这是强化学习的关键。**之前的工作倾向于计算两种状态(事件执行前和执行后)之间的差异，以确定奖励。 如果两种状态完全不同，那么测试工具就会持续提供较大的奖励，从而导致频繁地在两种状态之间跳跃，即使它们已经进行了过度探索。尽管一些奖励计算函数考虑了执行频率，但当大多数事件被执行多次时，问题就会再次出现。
       5. 为了解决上述挑战，并在Android GUI测试中释放机器学习的潜力，我们提出了一种基于强化学习的新方法——**q测试**。**q测试的策略被称为好奇心驱动的探索**，**它将测试导向它所好奇的状态。**更准确地说，Q测试保持了记忆功能，来记录之前访问过的部分状态。 强化学习奖励是根据当前状态与记忆中记录的状态的差异来计算的。与以往的研究不同，好奇心驱动的探索是一种动态的适应策略。通过适应性，它可以发现状态重要性的变化，并将持续调整特定事件的奖励。
       6. 为了提高测试效率，我们提出了一种神经网络，以**功能场景的粒度划分不同的状态**。q测试使用这个模块来比较状态和计算奖励。在它的帮助下，**q测试将优先努力覆盖不同的功能**，这有助于合理分配有限的测试时间，并将导致代码覆盖率在短时间内快速增长。我们收集了6k以上的样本来训练模型，它不仅可以用于强化学习。其他任务，包括状态压缩和代码推荐也可以从中受益。
       7. q测试还包括专门为Android应用程序设计的测试策略。我们解决了RecyclerView和ListView，以防止在不必要的测试中浪费时间。我们还考虑了**系统级别的事件，这有助于q测试找到一些复杂的bug。**
    3. **Q学习**
       1. Q学习是一种无模型强化学习的形式，其目标是学习如何将情境映射到行动，以便在未知环境中最大化数值奖励信号。强化学习的两个最显著的特征是试错搜索和延迟奖励。代理必须尝试不同的行动，以发现哪一种可能产生最多的奖励，而行动不仅会影响即时奖励，还会影响后续状态和未来奖励。
       2.  Q学习为代理提供了学习在马尔可夫环境中最优行动的能力，而不需要它们建立环境模型。我们观察到，一个Android应用程序测试过程可以被视为一个马尔可夫决策（MDP基于一组交互对象，即智能体和环境进行构建，所具有的要素包括状态、动作、策略和奖励。在MDP的模拟中，智能体会感知当前的系统状态，按策略对环境实施动作，从而改变环境的状态并得到奖励，奖励随时间的积累被称为回报）过程：**通过在测试操作导致应用程序的新状态时给予奖励，整个测试应该能够涵盖应用程序的更多功能。**这启发了我们将Q学习应用到Android自动化测试中。
    4.  **基于q学习的android测试**
       1. Android测试任务可以看作是一个马尔可夫决策过程，这使得强化学习发挥作用成为可能。我们设计了基于Q学习的探索策略，以指导测试工具朝向未揭示和不熟悉的功能。
       2. q测试的工作流。类似于MDP的过程，q测试在测试过程中与外部环境、待测应用程序(AUT)交互。在每个周期中，q测试首先使用UI自动监控器观察应用程序的当前状态。然后将状态St与部分观测状态进行比较。这些状态存储在缓冲区中，其作用类似于q测试的内存。通过训练神经网络提取状态特征并进行比较。**如果状态St与内存中的任何状态相似，比较器将给出一个小的奖励。否则，该模块将给出一个较大的奖励，并将状态St添加到内存缓冲区中。**奖励用于更新状态-动作对的值(St−1,At−1)。所有状态-动作对的值存储在q表中，并根据公式3更新。**每次到达一个新的状态时，q测试都会将相关的状态-动作对添加到Q表中，并用一个较大的值初始化它，以鼓励新事件的执行。**Q值更新后，Q测试将从St的GUI层次中推断出可执行事件，并参考Q表选择一个事件At。在大多数情况下，**将选择具有最高值的事件**。执行后，AUT将响应At，并开始另一个周期。
       3. 一个Android GUI测试问题在数学上被形式化为一个MDP，它可以用一个4元组定义，< S, A,P,R >。如何定义Android GUI测试任务的S, A, P和R将影响到测试的有效性和效率。
          - **S:状态**。更细的比较粒度将有利于测试，实现更高的代码覆盖率，发现更多的bug。由于这个原因，我们采用小部件组合作为比较标准。具体来说，Q测试使用UIAutomator来提取GUI层次结构。 UIAutomator转储当前接口中包含的小部件的信息。小部件以树状结构排列，其中非叶节点表示布局小部件，叶节点表示可执行小部件。q测试忽略了部件的一些属性，包括文本，以避免状态爆炸。 这些详细信息会干扰Q表的更新，降低测试效率。简而言之，状态St被定义为一个组合状态(w1, w2，…）其中wi是包含在St中的小部件的状态，它由选定的属性定义，这些属性包含一个索引属性来描述小部件在GUI层次树中的位置。
          - **A:动作**。在MDP中，我们将应用程序中的用户交互事件定义为动作，在本文中我们不区分事件和动作。与之前的工作类似，Q测试通过分析转储的小部件层次结构和相应的属性(如可点击、可滚动)推断当前状态下的可执行事件。由于每个事件都与特定的状态相关联，因此我们还可以**使用状态-动作对来表示应用程序状态中的可执行事件**。方程4描述了q测试用来选择下一个事件的ε-greedy策略。Q测试选择概率为1−ε的Q值最大的事件，选择概率为ε的随机事件。为了触发复杂的bug, q测试还考虑了系统级事件。在Q-testing中，ε值可以调整，其默认设置为0.2。
          - **P:转换函数**。**转换函数描述执行事件后应用程序将转换到的状态**。这是由AUT决定的，我们不能做任何改变。应该强调的是，执行事件的结果可以由内部变量的状态改变的非确定性转换。Q-testing使用Bellman函数更新Q值，其中状态-动作对(s,a)的值**受到s所能达到的所有状态的影响，因此在更新值时考虑了所有的转移信息。**
          - **R:奖励**。Q-testing在每次执行事件时都会获得奖励。提出了一个确定奖励的政策。
       4.  Q-testing采用好奇心驱动策略来测试AUT。强化学习任务研究了鼓励主体探索外部环境的好奇心，以解决稀少的奖励问题**。Q-testing提出的好奇心驱动策略可以引导测试工具探索不熟悉的状态，从而高效地覆盖代码和发现bug。**
          - 算法1描述了好奇心驱动的探索策略的算法。具体来说，**Q-testing维护一个状态缓冲区来存储之前访问过的部分状态**。这个缓冲区的作用类似于内存，它帮助Q-testing找出它**不熟悉的状态，也就是好奇的状态。**Q表存储了所有按活动(表示为行为)分组的状态-动作对及其值。每次到达一个状态时，q测试将直接查找q表，以找出可执行的操作。 如果第一次到达该状态，q测试将从GUI层次结构推断可执行操作并在Q-table中初始化。所有未执行的动作的初始值都设置为1000，这是一个很大的数字，以鼓励执行新动作，并且在执行后将其赋值为0。Q表就像一个轻量级的模型，可以加速测试过程，而且它还避免了建模不精确所带来的问题。
          - Q表还指导了下一个执行动作的选择，当从状态st执行一个动作at后，AUT将对它作出响应并传递到状态st +1(第10行)。 然后将st +1与存储在内存中的st +1进行比较，并根据它们的差异给予奖励(第11-21行)。**好奇心驱动策略将测试导向不熟悉的状态，当达到某种程度上与所有记忆状态不同的状态时，给予较大的奖励。**Q-testing还会通过在缓冲区中添加不熟悉的状态来更新内存，下一次访问该状态时，它就不再有吸引力了。 **我们将导致不熟悉功能的行动的奖励设置为500，根据Bellman方程，这将提高行动的价值。**对于探索AUT的新部分的q测试贡献不大的动作，奖励设置为-500。
          - 值得强调的是，该策略受益于Q值的传递特性，这使得无论当前状态的值是多少，都可以将Q测试导向有价值的状态。假设q测试在at执行一个事件，AUT转换到状态st +1，该状态类似于内存集中的一个状态。 然后将给予-500奖励，这可能会降低at的价值。然而，如果st +1是一个有价值的状态，可以导致在未探索的情况下，那么Q∗(st+1,at+1)，即存储在Q表中的状态st+1中所有状态-动作对的Q值的最大值，将是很大的。这导致at的值仍然会得到改进，因为在我们的实现中，γ被设置为0.99，以加强新状态的影响。这使得未被探索的功能更有可能被探索。
          - 此外，由于必须将当前状态与内存中的所有状态进行比较，因此需要采取一些措施来提高比较效率。首先，q测试在内存中存储特征向量而不是GUI层次信息。利用曼哈顿距离函数计算两个向量之间的相似度，无需重复提取特征。第二，向量按活动分组，一个向量只需与同一活动中的向量进行比较(第12行)。第三，我们提出了一个粗粒度的标准来划分状态，它在几个方面有利于测试过程。一方面，它限制了存储状态的数量，进一步减少了比较状态所花费的时间。另一方面，它鼓励q测试探索差异更大的状态，这将在短时间内导致高代码覆盖率，因为差异巨大的状态通常绑定到不同的代码
       5.  **针对android的策略：**
          - 除了基于好奇心的策略之外，q 测试还利用了其他基于Android应用特性而设计的策略，包括**特殊小部件的特殊处理和系统事件的注入。**
          - **RecyclerView和ListView是两个Android小部件**，它们能够以可滚动的方式显示视图集合。在大多数情况下，这些小部件将包含许多项，用户可以通过滚动查看新项。点击这些条目通常会导致类似的屏幕(具有相同的GUI层次结构和不同的内容)，并且只能触发相同的代码。现有的工作没有考虑到这些小部件，可能会浪费大量时间来测试不同的项。Q测试分析相关事件的结果。如果RecyclerView中的几个项目导致类似的状态，Q测试将忽略除第一个项目外的其他项目。这个策略可以节省很多时间，因为RecyclerView和ListView在我们日常使用的应用程序中很常见。
          - **系统事件**可以通过**触发复杂的错误而使测试受益**。与Stoat类似，q测试将三种系统级事件纳入考虑范围，包括用户操作(如屏幕旋转、电话呼叫)、广播消息和可从Android清单文件中提取的应用程序特定事件。**q测试在探索过程中随机执行系统级事件。这些事件不包括在Q-table中，因为可能的系统事件的数量非常大。一旦添加了它们，Q测试可能会尝试在每个状态中执行它们。**
    5. **场景划分模块：**
       1. 提出了一种新的粗粒度状态比较准则，用于确定好奇心驱动的探索策略中的奖励。该模块能够确定相同的功能场景是否处于两种状态。由比较模块确定的奖励将引导q测试首先覆盖不同的功能场景。**粗粒度状态划分避免了q测试一开始就陷入几个相同的场景，有助于合理分配有限的测试时间。这也会在短时间内导致高代码覆盖率，因为不同的场景通常绑定到不同的代码。** 更具体地说，在第一次到达一个功能场景时，可能会涉及大量的代码(例如初始化布局和交互事件的代码)，这是由Android框架的GUI驱动特性决定的。
       2. **场景划分的任务：**
          - 场景划分模块的场景定义类似于描述用户如何执行任务的用例的定义，也就是说，从用户的角度概述应用程序的行为。它们描述了应用程序提供的功能，但没有深入细节。但是，**由于不同的用户对功能的理解不同，一个功能可能包含一些子功能，因此场景的划分也可能不同。**例如，阅读新闻的功能可以是新闻应用的一个用例，但它也可以分为两种场景，一种是一般浏览新闻列表，另一种是阅读某条新闻的详细信息。但是，这不会对我们的场景划分模块造成问题。由于我们采用了基于神经网络的学习框架，可以通过输入不同的训练数据来调整划分场景的粒度。
          -  图3显示了Android应用程序中常见的三个典型场景，每个场景由两个GUI状态组成。正如我们所看到的，**在同一场景中的状态可能是非常不同的，现有的状态比较标准将很难做出正确的划分**。现有的研究依赖于手工定义的特性(例如，可执行事件、GUI层次结构、活动名称)来描述状态。 其中一些使用了一个阈值来灵活划分(例如，具有80%相同小部件的两个接口将被判定为相同状态)。然而，之前的方法不能满足我们的需求，需要考虑更多的属性，其中一些属性对于人类来说是很难提取的。以图3(a)为例。在浏览场景中有两种状态，其中包含一个RecyclerView来显示新闻项目。这两种状态可以通过滚动来相互访问。为了成功地确定这两个状态是在同一个场景中，首先，应该忽略项目的数量。其次，项目的GUI层次结构不应该被视为与其他小部件同等重要。尽管特征选择的工作量很大，但人工确定一个可能的阈值也是一项困难的任务，因为它通常依赖于大量的数据和实验。Q-testing利用擅长提取特征的神经网络来解决这些问题。
          -  Q-testing利用siamese网络**从判断两种状态是否处于同一情景的角度衡量两种状态之间的相似性。该网络能够通过样本对之间的相似度信息来学习变异的和选择性的表示。**
       3.  **训练数据集**
          - **插装的apk**。收集了大量的商业应用，每一个都包含丰富的场景。它们大都是闭源应用程序，我们在Android框架上进行研究，并利用Soot仪器几种方法和apk的状态来**收集运行时信息**，这将**为后续的标签过程提供更多的信息**。 具体来说，这些工具化的方法和语句对应于Activity、Fragment或Dialog的开始和销毁，**通常会随着场景的变化对界面的显示产生巨大的影响**。这些插装方法和语句的调用通常意味着场景的切换。
          -  **收集数据**。我们实现了一个自动收集样本数据的工具。它随机地探索应用程序，每次执行事件时，转换前后的状态将存储为一个样本对。
          - **增加数据**。在自动收集的数据中有一些问题，其中最重要的一个是，它只包括两个状态可以通过一个事件传递给对方的对。这种限制将导致训练数据和实际数据的分布不同，因为新状态必须与记忆中具有相同活动的所有状态进行比较。我们把收集到的数据分成几组，以反映他们的活动。然后，通过对同一活动中的状态进行随机映射，生成新的对。
          - **标记数据**。在数据收集步骤之后，我们将查看屏幕截图、收集到的每个状态对的运行时信息，并决定这对状态对是否属于同一场景的标签。 将标记好的样本送入神经网络进行训练。
    6. **q测试评估：**
       1. **该模型具有划分不同场景的能力**。由于bellman函数，我们的强化学习框架能够容忍场景划分模块所犯的错误。一方面，如果模块犯了错误，用一个大的数值错误地更新了事件的值，由于值的传播，它的值在经过多次触发和更新后仍然会被修正。另一方面，当到达一个导致重要状态的新场景时，神经网络错误地将事件的值更新为一个较小的值，bellman函数仍然会将被执行事件的值更新得更大。使用这个函数，所有后续事件的值将对前一个事件产生影响。综上所述，使用场景划分模块确定不同场景和计算强化学习奖励是可靠的。
       2. 代码覆盖率。
          - 和monkey的对比：monkey在最初几分钟内达到了最高的覆盖率。这主要是因为它以极高的速度执行事件，许多随机事件在一开始就会导致它进入新的状态。但是随着测试的不断进行，Monkey执行的冗余事件越来越多，效率开始下降。大约5分钟后，q测试占据了第一位，这证实了我们的好奇心驱动策略的有效性。**首先发现不同场景的策略使q测试能够在短时间内实现高代码覆盖率。当测试预算紧张时，这一点非常重要。**
          - 对于Monkey来说，它不需要在生成事件之前分析小部件层次结构。此外，它可以直接与几个重要的Android服务进行通信。这些特性使它能够高速生成事件。即使Monkey可以生成比其他程序多得多的事件，但它们中的大多数都是冗余的
          - q表就像一个轻量级模型，它将已探索的状态映射到操作，并可以节省推断可执行事件的时间。此外，在内存集中存储状态向量而不是原始GUI层次结构也有助于效率的提高。
          - 在侧边栏中，有6个候选选项和几个其他事件(例如返回，菜单)要选择，Q-testing选择“设置”选项的概率为30.69%。这一观察到的现象表明了好奇心驱动策略的力量和Q-learning的价值传播特性，探索重要的场景，可以导致更多的新场景。
       3. q测试触发故障的能力，这是其他工具无法替代的。
    7. 我们的结果可能不能推广到其他应用。我们通过从包含标准基准的相关工作中选择主题应用程序来减轻威胁。我们进一步完善基准测试，用流行的开源列表中的大型应用程序替换过时的应用程序。
    8. **相关工作**
       1. 随机测试。这种测试工具采用随机策略为Android应用生成输入。Monkey是最常用的Android测试工具，它通过与屏幕坐标的随机交互，生成用户事件的伪随机流。这个基本的随机策略在一些基准应用上执行得相当好。然而，生成的测试用例包含大量无效或冗余的事件，这将威胁到测试的有效性。
       2. 基于模型的测试。基于模型的方法使用动态或静态策略构建模型来描述应用程序的行为，然后从模型中派生测试用例来发现bug。由于测试用例是在构建模型的基础上生成的，它的准确性和完整性将是非常重要的。 Stoat[46]利用随机有限状态机模型来描述AUT的行为。在模型构建过程中，它推断可执行事件，并根据事件类型和执行频率等因素对其执行进行优先级排序。然后在测试生成过程中，Stoat利用MCMC抽样来指导派生测试用例的模型的变异。
       3.  基于机器学习的测试。机器学习已经应用于Android GUI测试，相关工作可分为两类。第一种方法有一个明确的培训过程，可以从之前的测试过程中学习，学到的经验随后将用于新的应用程序。另一项工作倾向于为每个应用独立建模或为测试下的应用适配一个通用模型。其中一些扩展了AutoBlackTest，没有明确的培训过程。
    9. 本文提出了一种基于Q-learning的Android自动测试方法——Q-testing。**Q-testing利用Q-table作为轻量级模型，同时使用好奇心驱动的策略探索不熟悉的功能。为了有效地确定q学习的奖励并进一步指导探索，提出了一个情景划分模块，该模块利用神经网络区分功能性情景。实验表明，Q-testing在代码覆盖和故障检测方面都优于当前最先进的Android GUI测试工具。**
19. An Infrastructure Approach to Improving Effectiveness of Android UI Testing Tools（提高Android用户界面测试工具有效性的基础设施方法）
    1. 由于Android应用程序质量保证的重要性，多年来研究人员开发了许多Android UI测试工具。然而，最近的研究表明，这些工具通常在流行的工业应用程序中实现较低的代码覆盖率。事实上，在具有大型代码库和复杂功能的流行工业应用程序上，如果给定合理的运行时间，大多数最先进的工具甚至无法超过简单的工具Monkey。我们的动机研究发现，这些工具执行两种类型的操作，UI层次捕获(捕获屏幕上内容的信息)和UI事件执行(执行UI事件，如点击)，通常使用Android框架的组件UIAutomator无效。总的来说，这两种操作平均占用给定测试时间的70%.
    2. 基于这一发现，为了**提高Android测试工具的有效性**，我们提出了Toller，这是一种对Android操作系统进行基础设施增强的工具。**Toller将自己注入到与被测试应用相同的虚拟机中，让Toller直接访问应用的运行时内存。** Toller因此能够直接(1)访问UI数据结构，从而捕获屏幕上的内容，而无需调用Android框架服务或远程过程调用(rpc)的开销，并且(2)调用UI事件处理程序，而无需执行UI事件。
    3. 基于上述发现，我们提出了Toller，一个为Android UI测试工具提供UI层次捕获和UI事件执行的基础设施增强的工具。**通过修改Android框架，Toller能够将自己注入到任何目标应用的虚拟机中，并访问该应用的运行时内存。**因此，**Toller可以直接读取应用程序的内部UI数据结构，并快速提取应用程序的UI层次结构，**避免了使用UIAutomator造成的大量开销，后者依赖于Android框架复杂的内部逻辑以及远程过程调用。**Toller还支持直接调用UI事件处理程序，从而消除了在执行模拟人类交互的低级UI事件(例如，等待长时间点击)上花费的不必要时间**，并且必须转换为基于UI层次结构的UI元素特定的事件。我们的实验表明，Toller可以大大减少上述两种操作所需的时间。
    4. 捕获屏幕上内容的信息(UI层次捕获)和执行UI事件(UI事件执行，比如点击)平均占用70%的测试运行时间。基于我们的研究结果，我们提出了Toller，一个为Android UI测试工具提供高效的UI层次捕获和UI事件执行的基础设施支持的工具。Toller可以显著地(1)减少测试工具所依赖的基础架构所使用的运行时间，(2)在给定合理的运行时间的情况下，提高这些工具的代码覆盖率和崩溃触发能力。
20. GUIDER: GUI Structure and Vision Co-guided Test Script Repair for Android Apps（GUIDER:Android应用程序的GUI结构和视觉共同引导测试脚本修复）
21. Understanding and Finding System Setting-Related Defects in Android Apps（了解并发现Android应用程序中与系统设置相关的缺陷）
22. WebEvo: Taming Web Application Evolution via Detecting Semantic Structure Changes（WebEvo：通过检测语义结构变化来驯服Web应用程序的演化）
23. GUI-Guided Test Script Repair for Mobile Apps（GUI引导的移动应用程序测试脚本修复）
24. Why My App Crashes? Understanding and Benchmarking Framework-specific Exceptions of Android apps（为什么我的应用程序崩溃？理解和基准化Android应用程序框架特定的例外情况） 